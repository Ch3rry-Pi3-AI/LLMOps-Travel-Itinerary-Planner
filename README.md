# ğŸ“Š **Centralised Logging Deployment â€” LLMOps Travel Itinerary Planner**

This branch introduces a complete **centralised logging pipeline** for the Travel Itinerary Planner using the **ELK stack**:

* **Filebeat** â€” Collects logs from every container/pod
* **Logstash** â€” Processes, transforms, and routes logs
* **Elasticsearch** â€” Stores logs in a powerful, searchable index
* **Kibana** â€” Visualises logs through dashboards and search

These four components work together to provide full observability of the application and cluster.
This is the first stage where the project gains **production-grade, cluster-wide log monitoring**.

## ğŸ—‚ï¸ **Project Structure (Updated)**

```text
LLMOPS-TRAVEL-ITINERARY-PLANNER/
â”œâ”€â”€ .venv/
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .python-version
â”œâ”€â”€ img/
â”‚   â””â”€â”€ streamlit/
â”‚       â””â”€â”€ streamlit_app.gif
â”œâ”€â”€ llmops_travel_itinerary_planner.egg-info/
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ uv.lock
â”œâ”€â”€ main.py
â”œâ”€â”€ app.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ k8s-deployment.yaml
â”œâ”€â”€ filebeat.yaml           # ğŸ“¡ Collects container logs from all cluster nodes
â”œâ”€â”€ logstash.yaml           # ğŸ”„ Receives logs and forwards them to Elasticsearch
â”œâ”€â”€ elasticsearch.yaml      # ğŸ—„ï¸ Stores logs in indexed search-optimised storage
â”œâ”€â”€ kibana.yaml             # ğŸ“Š Web UI for searching and visualising logs
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ chains/
â”‚   â”‚   â””â”€â”€ itinerary_chain.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ planner.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ custom_exception.py
â”‚       â”œâ”€â”€ logger.py
â”‚       â””â”€â”€ README.md
â””â”€â”€ README.md
```

Only the following files are new in this branch and are annotated here:

* `filebeat.yaml` ğŸ“¡
* `logstash.yaml` ğŸ”„
* `elasticsearch.yaml` ğŸ—„ï¸
* `kibana.yaml` ğŸ“Š

## ğŸ§© **Overview of the Logging Pipeline**

This stage introduces a full **ELK-style logging workflow** that enables:

* Cluster-wide log collection
* Central storage of logs
* Indexable log search
* Visual dashboards
* Debugging of failures in real time

Below is a clear beginner-friendly breakdown of what each component does and why it matters.

### ğŸ“¡ **Filebeat â€” Log Collector**

Filebeat runs as a **DaemonSet**, meaning **one pod per Kubernetes node**, ensuring:

* Every podâ€™s logs (`/var/log/containers/*.log`) are collected
* Kubernetes metadata (namespace, pod name, container name) is added
* Logs are forwarded to **Logstash**

**Intuition:**
Imagine Filebeat as a â€œtiny agentâ€ sitting on every machine, picking up every log file and forwarding it reliably.

### ğŸ”„ **Logstash â€” Log Router & Transformer**

Logstash receives logs from Filebeat and can:

* Filter them
* Parse them
* Transform them
* Route them

In this project, the configuration:

* Accepts logs on port **5044** (standard Beats input)
* Sends them straight to Elasticsearch

**Intuition:**
If Filebeat is the courier, Logstash is the post officeâ€”it sorts, organises, and routes deliveries.

### ğŸ—„ï¸ **Elasticsearch â€” Log Storage & Search Engine**

Elasticsearch stores logs as **documents** in an index.
It is optimised for:

* Full-text search
* Time-series queries
* Filtering & aggregation
* High-speed retrieval

In this deployment:

* Runs as a **single node** for simplicity
* Stores logs in a persistent volume
* No security enabled (development mode)

**Intuition:**
Elasticsearch is like a giant, super-fast search engine for your logs.

### ğŸ“Š **Kibana â€” Log Viewer & Dashboard Tool**

Kibana connects to Elasticsearch and provides:

* A web UI for viewing logs
* Filters, queries, dashboards
* Time-series visualisations
* Error and performance insights

Exposed via a **NodePort** so you can open it in your browser.

**Intuition:**
Kibana is your â€œcontrol centreâ€â€”search logs, view charts, identify errors.

:

## ğŸ”„ **How the Log Flow Works (Simple Example)**

Consider your Streamlit app pod writes:

```
2025-11-21 14:21:05 INFO Itinerary generated successfully
```

Here is what happens:

1. **Filebeat** (on the node) reads `/var/log/containers/app-xyz.log`.
2. It attaches metadata:

   ```
   namespace=default
   pod=streamlit-app-123
   container=streamlit-container
   ```
3. Filebeat forwards the enriched log to **Logstash**.
4. Logstash receives it and sends it to **Elasticsearch**.
5. Elasticsearch stores it as a document in an index:

   ```
   filebeat-2025.11.21
   ```
6. You open **Kibana**, search:

   ```
   app:streamlit AND level:INFO
   ```
7. You immediately see the log with filters and timestamps.

This provides real production-grade observability.

:

## ğŸš€ **How to Deploy the Logging Stack**

Assuming your cluster has the `logging` namespace:

```bash
kubectl create ns logging
```

Apply all four components:

```bash
kubectl apply -f elasticsearch.yaml
kubectl apply -f logstash.yaml
kubectl apply -f filebeat.yaml
kubectl apply -f kibana.yaml
```

Check pods:

```bash
kubectl get pods -n logging
```

Once Kibana is running:

```bash
minikube service kibana -n logging
```

Or, for cloud clusters:

```
http://<NODE_IP>:30601
```

## ğŸ§° **Integration Notes**

| Component            | Purpose                                                        |
| -------------------- | -------------------------------------------------------------- |
| `filebeat.yaml`      | Collects logs from all pods and forwards to Logstash           |
| `logstash.yaml`      | Receives Filebeat logs and forwards them to Elasticsearch      |
| `elasticsearch.yaml` | Stores logs in searchable indices                              |
| `kibana.yaml`        | Web UI for querying logs and building dashboards               |
| `app.py`             | Application producing logs                                     |
| `logger.py`          | Structured logging used by Filebeat â†’ Logstash â†’ Elasticsearch |

## âœ… **In summary**

This branch adds a **complete cluster-wide logging pipeline**, elevating your LLMOps Travel Itinerary Planner from a deployed app to a **monitorable, observable, production-ready service**.
