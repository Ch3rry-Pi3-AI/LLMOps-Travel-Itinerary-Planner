# ğŸŒ **LLMOps Travel Itinerary Planner â€” Project Overview**

This repository delivers a **complete end-to-end LLMOps pipeline** for a **Travel Itinerary Planner**, combining:

* **Custom LCEL chain logic**
* **Streamlit front-end user interface**
* **Containerisation via Docker**
* **Kubernetes deployment and orchestration**
* **Full ELK logging pipeline** (Filebeat â†’ Logstash â†’ Elasticsearch â†’ Kibana)
* **Cloud-based setup** through a **GCP Virtual Machine**

The system allows users to generate **personalised travel itineraries** using a Groq-powered LLM, interact with those results through a Streamlit web application, and observe all application logs through the ELK stack.

<p align="center">
  <img src="img/streamlit/streamlit_app.gif" alt="Streamlit App Demo" width="100%">
</p>

## ğŸ§© **Grouped Stages**

|     #     | Stage                                      | Description                                                                                                                                               |
| :-------: | :----------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------- |
|   **00**  | **Project Setup**                          | Created the initial folder structure, Python environment files, and project scaffolding.                                                                  |
| **01â€“02** | **Core LCEL Logic**                        | Built the itinerary generation chain and the planner module that orchestrates user preferences into structured itinerary outputs.                         |
|   **03**  | **Streamlit Application**                  | Implemented the user-facing Streamlit front end for entering destinations and generating itinerary recommendations.                                       |
|   **04**  | **Containerisation & Deployment Files**    | Authored the Dockerfile and Kubernetes deployment manifest to run the Streamlit application in a containerised environment.                               |
|   **05**  | **ELK Stack Manifests**                    | Created the full logging pipeline: Filebeat for log shipping, Logstash for processing, Elasticsearch for indexed storage, and Kibana for log exploration. |
| **06â€“08** | **Cloud & Cluster Configuration**          | Set up a GCP VM, installed Docker Engine, Minikube, kubectl, connected the GitHub repo, and configured firewall rules for external access.                |
|   **09**  | **Kubernetes Deployment (Application)**    | Deployed the Streamlit container to the Minikube cluster and exposed it via port-forwarding and external IP access.                                       |
|   **10**  | **ELK Stack Deployment & Log Exploration** | Deployed the Filebeat â†’ Logstash â†’ Elasticsearch â†’ Kibana pipeline and configured Kibana to inspect application logs.                                     |

## ğŸ—‚ï¸ **Project Structure**

```text
LLMOPS-TRAVEL-ITINERARY-PLANNER/
â”œâ”€â”€ .venv/                                # Python virtual environment
â”œâ”€â”€ .env                                  # Environment variables (GROQ API key)
â”œâ”€â”€ .gitignore                            # Git ignore rules
â”œâ”€â”€ .python-version                       # Python version pin
â”‚
â”œâ”€â”€ img/
â”‚   â””â”€â”€ streamlit/
â”‚       â””â”€â”€ streamlit_app.gif             # Demo animation of the Streamlit UI
â”‚
â”œâ”€â”€ llmops_travel_itinerary_planner.egg-info/  # Package metadata generated by setup.py
â”‚
â”œâ”€â”€ pyproject.toml                         # Project metadata and dependency configuration
â”œâ”€â”€ requirements.txt                       # Python dependency list
â”œâ”€â”€ setup.py                               # Package setup configuration
â”œâ”€â”€ uv.lock                                # Locked dependency versions for reproducibility
â”‚
â”œâ”€â”€ main.py                                # Entry script for manual chain testing
â”œâ”€â”€ app.py                                 # Streamlit front end that connects UI â†’ itinerary pipeline
â”‚
â”œâ”€â”€ Dockerfile                             # Container image definition for Streamlit app
â”œâ”€â”€ k8s-deployment.yaml                    # Kubernetes Deployment + Service for Streamlit app
â”‚
â”œâ”€â”€ filebeat.yaml                          # Collects container/node logs and ships them to Logstash
â”œâ”€â”€ logstash.yaml                          # Receives Filebeat logs, optionally processes them, forwards to Elasticsearch
â”œâ”€â”€ elasticsearch.yaml                     # Elasticsearch single-node deployment + storage PVC
â”œâ”€â”€ kibana.yaml                            # Kibana UI for exploring indexed logs
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ chains/
â”‚   â”‚   â””â”€â”€ itinerary_chain.py             # LCEL chain for generating itinerary text from user preferences
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ planner.py                     # Planner class that structures itinerary steps and interacts with the chain
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ config.py                      # Reads GROQ API key and other environment variables
â”‚   â”‚   â””â”€â”€ README.md                      # Documentation for configuration handling
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ custom_exception.py            # Custom exception class for unified error reporting
â”‚       â”œâ”€â”€ logger.py                      # Logging setup for app-level logs
â”‚       â””â”€â”€ README.md                      # Documentation for core utility modules
â”‚
â””â”€â”€ README.md                              # Root project documentation (this file)
```

## ğŸš€ **Summary**

The **LLMOps Travel Itinerary Planner** is a complete demonstration of how to operationalise an LLM-powered application from the ground up:

* **Custom LCEL chain + planner logic**
* **Interactive Streamlit interface**
* **Docker + Kubernetes deployment**
* **Complete ELK logging workflow**
* **Full cloud-based setup via GCP VM**

This project serves as a practical, scalable blueprint for deploying LLM applications in a **cloud-native, observable, production-ready environment**, while maintaining clean modular architecture and high development standards.